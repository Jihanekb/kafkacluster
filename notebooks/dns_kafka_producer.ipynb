{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed592b88",
   "metadata": {},
   "source": [
    "# Setup notebook to communicate with server and push information into Kafka Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52adc5aa",
   "metadata": {},
   "source": [
    "Welcome, please run the following lines of code to connect to the kafka server, make sure to store the .csv file in the same folder where this notebooks is. Have fun and good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1b6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka\n",
      "  Downloading kafka-1.3.5-py2.py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kafka\n",
      "Successfully installed kafka-1.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2682dd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Collecting numpy>=1.20.3\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51d84c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b65a16",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46cc38f4-a7f2-49f7-ac8d-a4bd87da9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (4.64.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2e6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from datetime import datetime\n",
    "from json import dumps\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ac49c",
   "metadata": {},
   "source": [
    "#### Connect to server and to topic to consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca17593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to bootstrap server\n"
     ]
    }
   ],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['kafka:9092'],\n",
    "                         value_serializer=lambda x: \n",
    "                         dumps(x).encode('utf-8'))\n",
    "if producer.bootstrap_connected():\n",
    "    print(f\"Successfully connected to bootstrap server\")\n",
    "else:\n",
    "    print(\"Couldn't connect to bootstrap server.\")\n",
    "\n",
    "TOPIC_NAME = \"ml-raw-dns\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e7dab",
   "metadata": {},
   "source": [
    "#### Define the function to push the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa755b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_message(producer_instance, topic, message):\n",
    "    producer_instance.send(topic, message)\n",
    "    producer_instance.flush()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc333756",
   "metadata": {},
   "source": [
    "#### Push the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ab2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "268065it [03:28, 1283.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch took 0:03:28.847168 time for ingesting data\n",
      "Ingestion Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"Kafka_dataset.csv\") as f:\n",
    "    start_time = datetime.now()\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        #print(i, line)\n",
    "        produce_message(producer_instance=producer, topic=TOPIC_NAME, message=line)\n",
    "    end_time = datetime.now()\n",
    "    print(f\"Batch took {end_time-start_time} time for ingesting data\")\n",
    "\n",
    "print(\"Ingestion Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
