{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from tensorflow import keras\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.float = float\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif as mi\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import river\n",
    "from river import compose\n",
    "from river import evaluate\n",
    "from river.metrics import Accuracy, Precision, Recall, F1\n",
    "from river import preprocessing\n",
    "from river import stream\n",
    "from skmultiflow.evaluation import EvaluateHoldout\n",
    "from skmultiflow.data import DataStream\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "from river.drift import ADWIN, PageHinkley\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import copy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "# or\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc557cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "    'ml-raw-dns',\n",
    "    bootstrap_servers=\"kafka:9092\",\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c61dfa-cfb0-4e4e-ad80-ef85268db658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your initial Keras model\n",
    "static_model = load('02.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab9227-bc27-4f90-a7d2-52936d4bbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-fitted scaler\n",
    "scaler = load('fitted_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58d63f-15d9-4365-8bb3-1b8bf0eb73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_model = copy.deepcopy(static_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b00ed-a61c-49a0-8a48-006312a9a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired window size\n",
    "window_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35216a-97e3-4a3c-9e8e-e2bc94fdfbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(data):\n",
    "    \n",
    "    # Decode byte string and split by comma\n",
    "    decoded_data = data.decode('utf-8').strip().split(',')\n",
    "    \n",
    "    # Remove additional characters from the 'Target Attack' field\n",
    "    target_attack = decoded_data[15].strip().strip('\\\\n\"')\n",
    "    \n",
    "    # Convert to appropriate data types\n",
    "    data_dict = {\n",
    "        'timestamp': decoded_data[0].strip('\"'),\n",
    "        'FQDN_count': int(decoded_data[1]),\n",
    "        'subdomain_length': int(decoded_data[2]),\n",
    "        'upper': int(decoded_data[3]),\n",
    "        'lower': int(decoded_data[4]),\n",
    "        'numeric': int(decoded_data[5]),\n",
    "        'entropy': float(decoded_data[6]),\n",
    "        'special': int(decoded_data[7]),\n",
    "        'labels': int(decoded_data[8]),\n",
    "        'labels_max': int(decoded_data[9]),\n",
    "        'labels_average': float(decoded_data[10]),\n",
    "        'longest_word': decoded_data[11],\n",
    "        'sld': decoded_data[12],\n",
    "        'len': int(decoded_data[13]),\n",
    "        'subdomain': int(decoded_data[14]),\n",
    "        'Target Attack': int(target_attack)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame([data_dict])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c9463-e903-47a0-abf2-0c3432a372d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_max(df):\n",
    "    for column in df.columns:\n",
    "        # Check if the column is numerical\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            max_value = df[column].max()\n",
    "            df[column].fillna(max_value, inplace=True)\n",
    "        else:\n",
    "            # For non-numeric columns, consider using mode (most frequent value) or another method\n",
    "            most_common = df[column].mode().iloc[0]\n",
    "            df[column].fillna(most_common, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a67a8f-5089-4092-b3a6-9ad4eb61fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.drop(columns='timestamp')\n",
    "    \n",
    "    df = impute_with_max(df)\n",
    "    \n",
    "    types = df.dtypes\n",
    "    #Indexes of categorical columns\n",
    "    categorical_indexes = (types == 'object')\n",
    "    #Indexes of numerical columns\n",
    "    numerical_indexes = ~categorical_indexes\n",
    "    \n",
    "    columns = df.columns\n",
    "    numerical_columns = columns[numerical_indexes]\n",
    "    categorical_columns = columns[categorical_indexes]\n",
    "    \n",
    "    # For outliers, we'll cap the values at the 1st and 99th percentiles for each numerical feature\n",
    "    for feature in numerical_columns:\n",
    "        # Calculate the 1st and 99th percentiles\n",
    "        lower_bound, upper_bound = df[feature].quantile([0.01, 0.99]).values\n",
    "        # Cap the outliers\n",
    "        df[feature] = np.clip(df[feature], lower_bound, upper_bound)\n",
    "        \n",
    "    # Length of the second-level domain\n",
    "    df['sld_length'] = df['sld'].apply(len)\n",
    "    # Presence of numeric characters in the second-level domain\n",
    "    df['sld_numeric'] = df['sld'].str.contains('\\d').astype(int)\n",
    "    \n",
    "    # Length of the longest word\n",
    "    df['longest_word_length'] = df['longest_word'].apply(len)\n",
    "    # Presence of numeric characters in the longest word\n",
    "    df['longest_word_numeric'] = df['longest_word'].str.contains('\\d').astype(int)\n",
    "    \n",
    "    n_features = 2**4\n",
    "    # Initialize the FeatureHasher\n",
    "    hasher_longest_word = FeatureHasher(n_features=n_features, input_type='string')\n",
    "    hasher_sld = FeatureHasher(n_features=n_features, input_type='string')\n",
    "    words_longest_word = df['longest_word'].astype(str).map(lambda x: x.split())\n",
    "    words_sld = df['sld'].astype(str).map(lambda x: x.split())\n",
    "    hashed_features_longest_word = hasher_longest_word.transform(words_longest_word)\n",
    "    hashed_features_sld = hasher_sld.transform(words_sld)\n",
    "    hashed_longest_word_df = pd.DataFrame(hashed_features_longest_word.toarray(),columns=[f'lw_hash_{i}' for i in range(hashed_features_longest_word.shape[1])])\n",
    "    hashed_sld_df = pd.DataFrame(hashed_features_sld.toarray(), columns=[f'sld_hash_{i}' for i in range(hashed_features_sld.shape[1])])\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    hashed_sld_df.reset_index(drop=True, inplace=True)\n",
    "    hashed_longest_word_df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.concat([df, hashed_sld_df, hashed_longest_word_df], axis=1)\n",
    "    \n",
    "    df = df.drop(['longest_word', 'sld'], axis=1)\n",
    "    features = ['FQDN_count', 'subdomain_length', 'lower', 'numeric', 'entropy',\n",
    "       'special', 'labels', 'labels_max', 'labels_average', 'sld_length',\n",
    "       'sld_numeric', 'longest_word_length', 'longest_word_numeric']\n",
    "    \n",
    "    y = df['Target Attack']\n",
    "    X = df[features]\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e603b-33f2-4a5f-a6ad-29737a90d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_data = []\n",
    "window_size = 1000\n",
    "performance_static = []\n",
    "performance_dynamic = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca529e-6782-4b08-96ef-f5ed7e00cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retrain(stream_features, adwin_delta=0.002, ph_lambda=50, ph_delta=0.005):\n",
    "    \"\"\"\n",
    "    Determine if the model should be retrained based on drift detection in the dataset.\n",
    "\n",
    "    :param stream_features: The stream of feature data points.\n",
    "    :param adwin_delta: Delta parameter for ADWIN.\n",
    "    :param ph_lambda: Lambda parameter for Page-Hinkley.\n",
    "    :param ph_delta: Delta parameter for Page-Hinkley.\n",
    "    :return: Boolean indicating whether retraining is necessary.\n",
    "    \"\"\"\n",
    "    adwin = ADWIN(delta=adwin_delta)\n",
    "    page_hinkley = PageHinkley(threshold=ph_lambda, delta=ph_delta)\n",
    "\n",
    "    for i in range(len(stream_features)):\n",
    "        x = stream_features.iloc[i].mean()\n",
    "        # Update the ADWIN and Page-Hinkley models with the feature data\n",
    "        # Assuming x is a numerical representation of the feature data point\n",
    "        adwin.update(x)\n",
    "        page_hinkley.update(x)\n",
    "\n",
    "        if adwin.drift_detected or page_hinkley.drift_detected:\n",
    "            return True  # Retraining required\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c40ae0-54e2-4bc5-977f-d9fa34387dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for message in consumer:\n",
    "    try:\n",
    "        # Deserialize your message here\n",
    "        df = deserialize(message.value) \n",
    "\n",
    "        # Add to window data\n",
    "        window_data.append(df)\n",
    "\n",
    "        # Check if the window is filled\n",
    "        if len(window_data) >= window_size:\n",
    "            # Convert window data to a suitable format for model input\n",
    "            window_df = pd.concat(window_data, ignore_index=True)\n",
    "\n",
    "            X , y = preprocess(window_df)\n",
    "            y = y.astype(int)\n",
    "            X_sc = scaler.transform(X)\n",
    "\n",
    "            # Evaluate the static model\n",
    "            y_pred_static = static_model.predict(X_sc)\n",
    "            accuracy_static = accuracy_score(y, y_pred_static)\n",
    "            precision_static = precision_score(y, y_pred_static)\n",
    "            recall_static = recall_score(y, y_pred_static)\n",
    "            f1_static = f1_score(y, y_pred_static)\n",
    "\n",
    "            # Store and print static model performance\n",
    "            metrics_static = {'accuracy': accuracy_static, 'precision': precision_static, 'recall': recall_static, 'f1_score': f1_static}\n",
    "            performance_static.append(metrics_static)\n",
    "            print(\"Static Model - Window:\", len(performance_static))\n",
    "            print(\"Accuracy:\", accuracy_static, \"Precision:\", precision_static, \"Recall:\", recall_static, \"F1 Score:\", f1_static)\n",
    "\n",
    "           # Evaluate the dynamic model\n",
    "            y_pred_dynamic = dynamic_model.predict(X_sc)\n",
    "            accuracy_dynamic = accuracy_score(y, y_pred_dynamic)\n",
    "            precision_dynamic = precision_score(y, y_pred_dynamic)\n",
    "            recall_dynamic = recall_score(y, y_pred_dynamic)\n",
    "            f1_dynamic = f1_score(y, y_pred_dynamic)\n",
    "\n",
    "            # Store and print dynamic model performance\n",
    "            metrics_dynamic = {'accuracy': accuracy_dynamic, 'precision': precision_dynamic, 'recall': recall_dynamic, 'f1_score': f1_dynamic}\n",
    "            performance_dynamic.append(metrics_dynamic)\n",
    "            print(\"Dynamic Model - Window:\", len(performance_dynamic))\n",
    "            print(\"Accuracy:\", accuracy_dynamic, \"Precision:\", precision_dynamic, \"Recall:\", recall_dynamic, \"F1 Score:\", f1_dynamic)\n",
    "            \n",
    "            \n",
    "            # Decide if retraining is necessary for the dynamic model\n",
    "            if should_retrain(X):  # Implement this function based on your criteria\n",
    "                print(\"Retraining dynamic model...\")\n",
    "                dynamic_model.partial_fit(X_sc, y)\n",
    "                print(\"Dynamic model retrained.\")\n",
    "\n",
    "            # Reset for the next window\n",
    "            window_data = []\n",
    "            window_labels = []\n",
    "\n",
    "    except ValueError as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a1c7f-0394-4ac8-bd28-29d4f2a5b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accuracy values for plotting\n",
    "accuracy_static = [metrics['precision'] for metrics in performance_static]\n",
    "accuracy_dynamic = [metrics['precision'] for metrics in performance_dynamic]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(accuracy_static, label='Static Model')\n",
    "plt.plot(accuracy_dynamic, label='Dynamic Model')\n",
    "plt.xlabel('Window Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accuracy values for plotting\n",
    "accuracy_static = [metrics['precision'] for metrics in performance_static]\n",
    "accuracy_dynamic = [metrics['precision'] for metrics in performance_dynamic]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(accuracy_static, label='Static Model')\n",
    "plt.plot(accuracy_dynamic, label='Dynamic Model')\n",
    "plt.xlabel('Window Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accuracy values for plotting\n",
    "accuracy_static = [metrics['precision'] for metrics in performance_static]\n",
    "accuracy_dynamic = [metrics['precision'] for metrics in performance_dynamic]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(accuracy_static, label='Static Model')\n",
    "plt.plot(accuracy_dynamic, label='Dynamic Model')\n",
    "plt.xlabel('Window Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accuracy values for plotting\n",
    "accuracy_static = [metrics['precision'] for metrics in performance_static]\n",
    "accuracy_dynamic = [metrics['precision'] for metrics in performance_dynamic]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(accuracy_static, label='Static Model')\n",
    "plt.plot(accuracy_dynamic, label='Dynamic Model')\n",
    "plt.xlabel('Window Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
